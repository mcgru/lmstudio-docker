
services:
  lmstudio:
    image: lmstudio:latest
    container_name: lmstudio
    restart: unless-stopped
    build:
      context: "$HOME/LMStudio"
    ports:
      - "1234:1234"
    volumes:
      - ./data:/root/.cache/lm-studio/models
      - ./http-server-config.json:/http-server-config.json:ro
      - ./docker-entrypoint.sh:/usr/local/bin/docker-entrypoint.sh:ro
    environment:
      - CONTEXT_LENGTH=${CONTEXT_LENGTH:-131072}
      - MODEL_PATH=${MODEL_PATH:-Qwen/Qwen2.5-Coder-14B-Instruct-GGUF}
      - MODEL_IDENTIFIER=${MODEL_IDENTIFIER:-qwen2.5-coder-14b-instruct}

      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0

#    runtime: nvidia
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - capabilities: [gpu]
#              driver: nvidia
#              count: 2

###    command: ["/start_services.sh"]
####### if you need distinct network - uncomment here and lower
#    networks:
#      - homelab_homelabnet
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.lmstudio.entrypoints=http"
      - "traefik.http.routers.lmstudio.rule=Host(`${DOMAIN_NAME}`)"
      - "traefik.http.services.lmstudio.loadbalancer.server.port=1234"

#networks:
#  homelab_homelabnet:
#    external: true

